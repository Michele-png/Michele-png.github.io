{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Setup Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated version at C:\\Users\\User\\AppData\\Roaming\\MobaXterm\\slash\\RemoteFiles\\264144_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile, Levenshtein, pycountry, re, json\n",
    "from textdistance import jaro_winkler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Importing and Elaborating Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract Firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pBook Tab \n",
    "path = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\comlist_forpatent.xlsx' \n",
    "cols = ['UID', 'CompanyName', 'Country/Region']\n",
    "df_firms = pd.read_excel(path, usecols=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shorten Firms Country/Region\n",
    "Note on Missing Values Refill for Firms Country/Region: \n",
    "- Firm Bygg had state California, but Country/Region empty, it was manually filled in the excel sheet as United States; \n",
    "- CELL AGRITECH SDN BHD had Country/Region empty, a quick google search revealts they are headquartered in Malaysia; \n",
    "- Health Sources Nutrition Co.,Ltd. had no Coutry/Region, but its headquarters are reported to be in Heifei, i.e. Mainland China. \n",
    "\n",
    "These changes were made directly in the source table i.e. pBook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Country/Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>657135</td>\n",
       "      <td>100Foods</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>769415</td>\n",
       "      <td>108Labs</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>938559</td>\n",
       "      <td>1Ness Foods Pvt. Ltd.</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326285</td>\n",
       "      <td>3D Bio-Tissues Ltd.</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>832680</td>\n",
       "      <td>4U Free From</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>978656</td>\n",
       "      <td>Zero Meat</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>551962</td>\n",
       "      <td>ZhenMeat</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>833239</td>\n",
       "      <td>Zikooin Company</td>\n",
       "      <td>KR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>653912</td>\n",
       "      <td>Zoglo's (brand of Soglowek)</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>406887</td>\n",
       "      <td>Zona Cerealista</td>\n",
       "      <td>BR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1476 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UID                  CompanyName Country/Region\n",
       "0     657135                     100Foods             BR\n",
       "1     769415                      108Labs             US\n",
       "2     938559       1Ness Foods Pvt. Ltd.              IN\n",
       "3     326285          3D Bio-Tissues Ltd.             GB\n",
       "4     832680                 4U Free From             ES\n",
       "...      ...                          ...            ...\n",
       "1471  978656                    Zero Meat             JP\n",
       "1472  551962                     ZhenMeat             CN\n",
       "1473  833239              Zikooin Company             KR\n",
       "1474  653912  Zoglo's (brand of Soglowek)             CA\n",
       "1475  406887              Zona Cerealista             BR\n",
       "\n",
       "[1476 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "country_name_to_code = {country.name: country.alpha_2 for country in pycountry.countries}\n",
    "mapping_missing_countries = {'Czech Republic' : 'CZ',\n",
    "                        'India ' : 'IN',\n",
    "                        'Mainland China' : 'CN',\n",
    "                        'Russia' : 'RU',\n",
    "                        'Scotland' : 'GB',\n",
    "                        'South Korea' : 'KR',\n",
    "                        'Taiwan' : 'TW',\n",
    "                        'Venezuela' : 'VE',\n",
    "                        'Vietnam' : 'VN',\n",
    "                        'latvia' : 'LV'}\n",
    "                        \n",
    "country_name_to_code.update(mapping_missing_countries)\n",
    "df_firms['Country/Region'] = df_firms['Country/Region'].map(country_name_to_code)\n",
    "df_firms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract People\n",
    "path_people1 = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Patstat2021a\\data_PATSTAT_Global_2021_Autumn\\tls206_part01.zip'\n",
    "csv_people1 = 'tls206_part01.csv'\n",
    "path_people2 = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Patstat2021a\\data_PATSTAT_Global_2021_Autumn\\tls206_part02.zip'\n",
    "csv_people2 = 'tls206_part02.csv'\n",
    "\n",
    "cols_people = ['person_id', 'person_name', 'person_ctry_code', 'psn_sector']\n",
    "\n",
    "with zipfile.ZipFile(path_people1, 'r') as z:\n",
    "    with z.open(csv_people1) as f:\n",
    "            d_people1 = pd.read_csv(f, nrows = None, usecols=cols_people)\n",
    "        \n",
    "with zipfile.ZipFile(path_people2, 'r') as z:\n",
    "    with z.open(csv_people2) as f:\n",
    "            d_people2 = pd.read_csv(f, nrows = None, usecols=cols_people)\n",
    "\n",
    "# concatenate \n",
    "d_people = pd.concat([d_people1, d_people2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter People for Applicants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>applicant_name</th>\n",
       "      <th>applicant_ctry_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Nokia Corporation</td>\n",
       "      <td>FI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>NOKIA MOBILE PHONES LTD.</td>\n",
       "      <td>FI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>MEDIMMUNE LIMITED</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>CAMBRIDGE ANTIBODY TECHNOLOGY LIMITED</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Cambridge Antibody Technology Limited</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981848</th>\n",
       "      <td>79307363</td>\n",
       "      <td>VERTEX TRADING CO., LTD.</td>\n",
       "      <td>WS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981849</th>\n",
       "      <td>79307369</td>\n",
       "      <td>DETNET SOUTH AFRICA (PROPRIETARY) LIMITED</td>\n",
       "      <td>ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981850</th>\n",
       "      <td>79307373</td>\n",
       "      <td>GLENCORE OPERATION SOUTH AFRICA (PROPRIETARY) ...</td>\n",
       "      <td>ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981851</th>\n",
       "      <td>79307380</td>\n",
       "      <td>PowerOptimal(Pty) Ltd</td>\n",
       "      <td>ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981852</th>\n",
       "      <td>79307382</td>\n",
       "      <td>WEST COAST GROUP (PTY) LTD</td>\n",
       "      <td>ZA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9981853 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         applicant_id                                     applicant_name   \n",
       "0                   1                                  Nokia Corporation  \\\n",
       "1                   6                           NOKIA MOBILE PHONES LTD.   \n",
       "2                   8                                  MEDIMMUNE LIMITED   \n",
       "3                  15              CAMBRIDGE ANTIBODY TECHNOLOGY LIMITED   \n",
       "4                  17              Cambridge Antibody Technology Limited   \n",
       "...               ...                                                ...   \n",
       "9981848      79307363                           VERTEX TRADING CO., LTD.   \n",
       "9981849      79307369          DETNET SOUTH AFRICA (PROPRIETARY) LIMITED   \n",
       "9981850      79307373  GLENCORE OPERATION SOUTH AFRICA (PROPRIETARY) ...   \n",
       "9981851      79307380                              PowerOptimal(Pty) Ltd   \n",
       "9981852      79307382                         WEST COAST GROUP (PTY) LTD   \n",
       "\n",
       "        applicant_ctry_code  \n",
       "0                        FI  \n",
       "1                        FI  \n",
       "2                        GB  \n",
       "3                        GB  \n",
       "4                        GB  \n",
       "...                     ...  \n",
       "9981848                  WS  \n",
       "9981849                  ZA  \n",
       "9981850                  ZA  \n",
       "9981851                  ZA  \n",
       "9981852                  ZA  \n",
       "\n",
       "[9981853 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a better method to obtain a list of applicants\n",
    "df_applicants = d_people.loc[d_people['psn_sector']=='COMPANY', d_people.columns!='psn_sector']\n",
    "df_applicants.rename(columns={'person_id':'applicant_id', 'person_name':'applicant_name', 'person_ctry_code':'applicant_ctry_code'}, inplace=True)\n",
    "df_applicants.reset_index(inplace=True, drop=True)\n",
    "del d_people, d_people1, d_people2\n",
    "df_applicants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Missing-Management and Standardizations of Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Signal Applicants Country Code in PATSTAT\n",
    "Recall that there is no need to harmonize country code in PATSTAT. \n",
    "We could have to refill person name as it sometimes is missing, and we could have rather than nan coutry code, empyty coutry code in the shape of '  '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 9981853 applicants and 97 of them have the coutry code missing\n",
      "there are 9981853 applicants and 5212468 of them have the coutry code empty\n"
     ]
    }
   ],
   "source": [
    "# Check how many applicants have empty coutry code\n",
    "n = df_applicants['applicant_ctry_code'].isna().sum()\n",
    "k = df_applicants.loc[df_applicants['applicant_ctry_code'] == \"  \", :].count()[0]\n",
    "print(f'there are {df_applicants.shape[0]} applicants and {n} of them have the coutry code missing')\n",
    "print(f'there are {df_applicants.shape[0]} applicants and {k} of them have the coutry code empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whenever the coutry code is missing, replace it with XX\n",
    "df_applicants.loc[df_applicants['applicant_ctry_code']=='  ', 'applicant_ctry_code'] = 'XX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standardize Companies and Firms Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the standardization dictionary from the JSON file\n",
    "with open(\"standardization_dict.json\", \"r\") as json_file:\n",
    "    standardization_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_names(name):\n",
    "\n",
    "    try:\n",
    "        name = re.sub(r'[^\\w\\s]', '', name.upper()) #leave only numbers and lettersn turn characters upper\n",
    "        for key, val in standardization_dict.items(): #loop over legal designations and their corresponding WOS structure\n",
    "            key, val = key.strip(), val.strip()\n",
    "            name = name.replace(key, val)\n",
    "        return name.strip()  # Strip any leading/trailing spaces\n",
    "    except:\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EDISON GAS UNIV 1512 AV'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Edison, Gas UNIVERSITIES 15/12 Av.'\n",
    "standardize_names(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear names in both databases\n",
    "df_firms['Clear Name Firm'] = (df_firms['CompanyName'].apply(standardize_names)).copy(deep=True)\n",
    "df_applicants['Clear Name Applicant'] = (df_applicants['applicant_name'].apply(standardize_names)).copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Fuzzy Matching of pBook Firms and Patstat Applicant Company Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>applicant_name</th>\n",
       "      <th>applicant_ctry_code</th>\n",
       "      <th>Clear Name Applicant</th>\n",
       "      <th>UID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Clear Name Firm</th>\n",
       "      <th>Match Type</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>431494</td>\n",
       "      <td>Valio Ltd.</td>\n",
       "      <td>FI</td>\n",
       "      <td>VALIO LTD</td>\n",
       "      <td>896158</td>\n",
       "      <td>Valio LTD</td>\n",
       "      <td>FI</td>\n",
       "      <td>VALIO LTD</td>\n",
       "      <td>Alphanumeric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1287001</td>\n",
       "      <td>Valio Ltd.</td>\n",
       "      <td>FI</td>\n",
       "      <td>VALIO LTD</td>\n",
       "      <td>896158</td>\n",
       "      <td>Valio LTD</td>\n",
       "      <td>FI</td>\n",
       "      <td>VALIO LTD</td>\n",
       "      <td>Alphanumeric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3265298</td>\n",
       "      <td>VALIO LTD.</td>\n",
       "      <td>FI</td>\n",
       "      <td>VALIO LTD</td>\n",
       "      <td>896158</td>\n",
       "      <td>Valio LTD</td>\n",
       "      <td>FI</td>\n",
       "      <td>VALIO LTD</td>\n",
       "      <td>Alphanumeric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3392149</td>\n",
       "      <td>Valio Ltd.</td>\n",
       "      <td>FI</td>\n",
       "      <td>VALIO LTD</td>\n",
       "      <td>896158</td>\n",
       "      <td>Valio LTD</td>\n",
       "      <td>FI</td>\n",
       "      <td>VALIO LTD</td>\n",
       "      <td>Alphanumeric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3392153</td>\n",
       "      <td>Valio Ltd.</td>\n",
       "      <td>FI</td>\n",
       "      <td>VALIO LTD</td>\n",
       "      <td>896158</td>\n",
       "      <td>Valio LTD</td>\n",
       "      <td>FI</td>\n",
       "      <td>VALIO LTD</td>\n",
       "      <td>Alphanumeric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>77477663</td>\n",
       "      <td>Wild Earth, Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>WILD EARTH INC</td>\n",
       "      <td>358287</td>\n",
       "      <td>Wild Earth Inc</td>\n",
       "      <td>US</td>\n",
       "      <td>WILD EARTH INC</td>\n",
       "      <td>Alphanumeric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>74518409</td>\n",
       "      <td>DAIZ Inc.</td>\n",
       "      <td>JP</td>\n",
       "      <td>DAIZ INC</td>\n",
       "      <td>610404</td>\n",
       "      <td>DAIZ, Inc.</td>\n",
       "      <td>JP</td>\n",
       "      <td>DAIZ INC</td>\n",
       "      <td>Alphanumeric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>77359949</td>\n",
       "      <td>DAIZ INC.</td>\n",
       "      <td>JP</td>\n",
       "      <td>DAIZ INC</td>\n",
       "      <td>610404</td>\n",
       "      <td>DAIZ, Inc.</td>\n",
       "      <td>JP</td>\n",
       "      <td>DAIZ INC</td>\n",
       "      <td>Alphanumeric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>74844987</td>\n",
       "      <td>The Better Meat Co.</td>\n",
       "      <td>US</td>\n",
       "      <td>THE BETTER MEAT CO</td>\n",
       "      <td>493241</td>\n",
       "      <td>The Better Meat Co.</td>\n",
       "      <td>US</td>\n",
       "      <td>THE BETTER MEAT CO</td>\n",
       "      <td>Alphanumeric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>77224457</td>\n",
       "      <td>THE BETTER MEAT COMPANY</td>\n",
       "      <td>US</td>\n",
       "      <td>THE BETTER MEAT CO</td>\n",
       "      <td>493241</td>\n",
       "      <td>The Better Meat Co.</td>\n",
       "      <td>US</td>\n",
       "      <td>THE BETTER MEAT CO</td>\n",
       "      <td>Alphanumeric</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     applicant_id           applicant_name applicant_ctry_code   \n",
       "0          431494               Valio Ltd.                  FI  \\\n",
       "1         1287001               Valio Ltd.                  FI   \n",
       "2         3265298               VALIO LTD.                  FI   \n",
       "3         3392149               Valio Ltd.                  FI   \n",
       "4         3392153               Valio Ltd.                  FI   \n",
       "..            ...                      ...                 ...   \n",
       "208      77477663          Wild Earth, Inc                  US   \n",
       "209      74518409                DAIZ Inc.                  JP   \n",
       "210      77359949                DAIZ INC.                  JP   \n",
       "211      74844987      The Better Meat Co.                  US   \n",
       "212      77224457  THE BETTER MEAT COMPANY                  US   \n",
       "\n",
       "    Clear Name Applicant     UID          CompanyName Country/Region   \n",
       "0              VALIO LTD  896158            Valio LTD             FI  \\\n",
       "1              VALIO LTD  896158            Valio LTD             FI   \n",
       "2              VALIO LTD  896158            Valio LTD             FI   \n",
       "3              VALIO LTD  896158            Valio LTD             FI   \n",
       "4              VALIO LTD  896158            Valio LTD             FI   \n",
       "..                   ...     ...                  ...            ...   \n",
       "208       WILD EARTH INC  358287       Wild Earth Inc             US   \n",
       "209             DAIZ INC  610404          DAIZ, Inc.              JP   \n",
       "210             DAIZ INC  610404          DAIZ, Inc.              JP   \n",
       "211   THE BETTER MEAT CO  493241  The Better Meat Co.             US   \n",
       "212   THE BETTER MEAT CO  493241  The Better Meat Co.             US   \n",
       "\n",
       "        Clear Name Firm    Match Type  Score  \n",
       "0             VALIO LTD  Alphanumeric    NaN  \n",
       "1             VALIO LTD  Alphanumeric    NaN  \n",
       "2             VALIO LTD  Alphanumeric    NaN  \n",
       "3             VALIO LTD  Alphanumeric    NaN  \n",
       "4             VALIO LTD  Alphanumeric    NaN  \n",
       "..                  ...           ...    ...  \n",
       "208      WILD EARTH INC  Alphanumeric    NaN  \n",
       "209            DAIZ INC  Alphanumeric    NaN  \n",
       "210            DAIZ INC  Alphanumeric    NaN  \n",
       "211  THE BETTER MEAT CO  Alphanumeric    NaN  \n",
       "212  THE BETTER MEAT CO  Alphanumeric    NaN  \n",
       "\n",
       "[213 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use alphanumeric matching on names without legal designation\n",
    "df_perfect = pd.merge(df_applicants, df_firms, how='inner', left_on='Clear Name Applicant', right_on='Clear Name Firm')\n",
    "df_perfect['Match Type'] = 'Alphanumeric'\n",
    "df_perfect['Score'] = np.nan\n",
    "df_perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 110. GiB for an array with shape (9981853, 1476) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-10db7cb39bef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Apply get_jaro_distance on each couple of names from firms on the horizontal axis, and applicants on the vertical axis.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Save in JW whether the result exceeded the threshold or not.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mJW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorized_JW\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbroadcasted_firms_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbroadcasted_applicants_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Place the firms index as columns of the resulting boolean dataframe, and the applicant index as its index. Thus create a DataFrame.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2327\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2329\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2410\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2412\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2414\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 110. GiB for an array with shape (9981853, 1476) and data type object"
     ]
    }
   ],
   "source": [
    "# Fully Broadcasted JW Distance Implementation\n",
    "\n",
    "# Set threshold for the Jaro Winkler score of two names. If their score exceeds the threshold, they are considered equal. \n",
    "threshold = 0.935\n",
    "# vectorize the pyfunction get_jaro_distance so that it can take as input arrays of the same shape. \n",
    "vectorized_JW = np.vectorize(jaro_winkler)\n",
    "\n",
    "# Create the ndarrays on which to apply vectorized_JW\n",
    "firms_names = df_firms['Clear Name Firm'].values\n",
    "applicants_names = df_applicants['Clear Name Applicant'].values\n",
    "applicants_names = np.reshape(applicants_names, (-1, 1))\n",
    "broadcasted_firms_names, broadcasted_applicants_names = np.broadcast_arrays(firms_names, applicants_names)\n",
    "# Apply get_jaro_distance on each couple of names from firms on the horizontal axis, and applicants on the vertical axis. \n",
    "# Save in JW whether the result exceeded the threshold or not. \n",
    "JW = vectorized_JW(broadcasted_firms_names, broadcasted_applicants_names)\n",
    "\n",
    "# Place the firms index as columns of the resulting boolean dataframe, and the applicant index as its index. Thus create a DataFrame.\n",
    "# Then stack it and reset the index as to obtain a form [applicant_index][firm_index][Jaro-Winkler score of the names at those positions]\n",
    "JW = pd.DataFrame(JW, index=df_applicants['Clear Name Applicant'].index, columns=df_firms['Clear Name Firm'].index)\n",
    "JW = JW.stack()\n",
    "JW = JW.reset_index()\n",
    "JW.columns = ['applicant_index', 'firm_index', 'JW_score']\n",
    "\n",
    "# Retreive the couples of applicant and firm indeces which scored above the threshold, store them in filtering masks. Then, apply these marsks on the original\n",
    "# firm and applicant dataframes to recover DataFrames with full rows the names of which exceeded the threshold. Concatenate them,  insert Match Type = Jaro-Winkler,\n",
    "# and insert the JW score of the corresponding names\n",
    "index_mask = JW.loc[(JW['JW_score']>threshold), ['applicant_index', 'firm_index']] \n",
    "applicants_to_append = (df_applicants.loc[index_mask['applicant_index']]).reset_index(drop=True)\n",
    "firms_to_append = (df_firms.loc[index_mask['firm_index']]).reset_index(drop=True)\n",
    "df_JW = pd.concat([applicants_to_append, firms_to_append], axis=1)\n",
    "df_JW['Match Type'] = 'Jaro-Winkler'\n",
    "df_JW['Score'] = JW.loc[index_mask.index, 'JW_score'].values\n",
    "\n",
    "df_JW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>applicant_name</th>\n",
       "      <th>applicant_ctry_code</th>\n",
       "      <th>Clear Name Applicant</th>\n",
       "      <th>UID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Clear Name Firm</th>\n",
       "      <th>Match Type</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17312</td>\n",
       "      <td>VALEO</td>\n",
       "      <td>FR</td>\n",
       "      <td>VALEO</td>\n",
       "      <td>357006</td>\n",
       "      <td>Paleo</td>\n",
       "      <td>BE</td>\n",
       "      <td>PALEO</td>\n",
       "      <td>Levenshtein</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17406</td>\n",
       "      <td>MEURA</td>\n",
       "      <td>BE</td>\n",
       "      <td>MEURA</td>\n",
       "      <td>586864</td>\n",
       "      <td>Heura</td>\n",
       "      <td>ES</td>\n",
       "      <td>HEURA</td>\n",
       "      <td>Levenshtein</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   applicant_id applicant_name applicant_ctry_code Clear Name Applicant   \n",
       "0         17312          VALEO                  FR                VALEO  \\\n",
       "1         17406          MEURA                  BE                MEURA   \n",
       "\n",
       "      UID CompanyName Country/Region Clear Name Firm   Match Type  Score  \n",
       "0  357006       Paleo             BE           PALEO  Levenshtein      1  \n",
       "1  586864       Heura             ES           HEURA  Levenshtein      1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fully Broadcasted LV Distance Implementation\n",
    "\n",
    "# Set threshold for the Levenstein score of two names, which is the max number of character changes between two strings for them to be considered equal\n",
    "threshold = 2\n",
    "# vectorize the pyfunction get_jaro_distance so that it can take as input arrays of the same shape. \n",
    "vectorized_LV = np.vectorize(Levenshtein.distance)\n",
    "\n",
    "# Create the arrays on which to apply vectorized_LV\n",
    "firms_names = df_firms['Clear Name Firm'].values\n",
    "applicants_names = df_applicants['Clear Name Applicant'].values\n",
    "applicants_names = np.reshape(applicants_names, (-1, 1))\n",
    "broadcasted_firms_names, broadcasted_applicants_names = np.broadcast_arrays(firms_names, applicants_names)\n",
    "# Apply Levenstein distance on each couple of names from firms on the horizontal axis, and applicants on the vertical axis. \n",
    "# Save in LV whether the result is below the threshold or not. \n",
    "LV = vectorized_LV(broadcasted_firms_names, broadcasted_applicants_names)\n",
    "\n",
    "# Place the firms index as columns of the resulting boolean dataframe, and the applicant index as its index. Thus create a DataFrame.\n",
    "# Then stack it and reset the index as to obtain a form [applicant_index][firm_index][boolean of whether the names at those positions are below the threshold]\n",
    "LV = pd.DataFrame(LV, index=df_applicants['Clear Name Applicant'].index, columns=df_firms['Clear Name Firm'].index)\n",
    "LV = LV.stack()\n",
    "LV = LV.reset_index()\n",
    "LV.columns = ['applicant_index', 'firm_index', 'LV_score']\n",
    "\n",
    "# Retreive the couples of applicant and firm indeces which scored true, store them in filtering masks. Then, apply these marsks on the original\n",
    "# firm and applicant dataframes to recover DataFrames with full rows the names of which exceeded the threshold. Concatenate them and insert Match Type = Levenshtein. \n",
    "index_mask = LV.loc[(LV['LV_score']<threshold), ['applicant_index', 'firm_index']] \n",
    "applicants_to_append = (df_applicants.loc[index_mask['applicant_index']]).reset_index(drop=True)\n",
    "firms_to_append = (df_firms.loc[index_mask['firm_index']]).reset_index(drop=True)\n",
    "df_LV = pd.concat([applicants_to_append, firms_to_append], axis=1)\n",
    "df_LV['Match Type'] = 'Levenshtein'\n",
    "df_LV['Score'] = LV.loc[index_mask.index, 'LV_score'].values\n",
    "\n",
    "df_LV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>applicant_name</th>\n",
       "      <th>applicant_ctry_code</th>\n",
       "      <th>UID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Match Type</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50051403</td>\n",
       "      <td>Impossible Foods Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>765140</td>\n",
       "      <td>Impossible Foods</td>\n",
       "      <td>US</td>\n",
       "      <td>Jaro-Winkler</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17312</td>\n",
       "      <td>VALEO</td>\n",
       "      <td>FR</td>\n",
       "      <td>357006</td>\n",
       "      <td>Paleo</td>\n",
       "      <td>BE</td>\n",
       "      <td>Levenshtein</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17406</td>\n",
       "      <td>MEURA</td>\n",
       "      <td>BE</td>\n",
       "      <td>586864</td>\n",
       "      <td>Heura</td>\n",
       "      <td>ES</td>\n",
       "      <td>Levenshtein</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   applicant_id         applicant_name applicant_ctry_code     UID   \n",
       "0      50051403  Impossible Foods Inc.                  US  765140  \\\n",
       "1         17312                  VALEO                  FR  357006   \n",
       "2         17406                  MEURA                  BE  586864   \n",
       "\n",
       "        CompanyName Country/Region    Match Type  Score  \n",
       "0  Impossible Foods             US  Jaro-Winkler   0.96  \n",
       "1             Paleo             BE   Levenshtein   1.00  \n",
       "2             Heura             ES   Levenshtein   1.00  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the resulting tables togerther\n",
    "df_fuzzy = pd.concat([df_perfect, df_JW, df_LV], axis = 0)\n",
    "df_fuzzy = df_fuzzy.loc[:, (df_fuzzy.columns != 'Clear Name Applicant')&(df_fuzzy.columns != 'Clear Name Firm')]\n",
    "df_fuzzy.reset_index(drop=True, inplace=True)\n",
    "df_fuzzy.drop_duplicates(inplace=True)\n",
    "df_fuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Additional Filters and Disambiguations\n",
    "Use country code to disambiguate between rows with double matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Quality of Location Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_quality(applicant_ctry, firm_ctry):\n",
    "    if (applicant_ctry == 'XX') or (firm_ctry == 'XX'):\n",
    "        return 'Inconclusive'\n",
    "    elif (applicant_ctry == firm_ctry):\n",
    "        return 'Matched'\n",
    "    elif (applicant_ctry != firm_ctry):\n",
    "        return 'Not Matched'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>applicant_name</th>\n",
       "      <th>applicant_ctry_code</th>\n",
       "      <th>UID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Match Type</th>\n",
       "      <th>Score</th>\n",
       "      <th>Location Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50051403</td>\n",
       "      <td>Impossible Foods Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>765140</td>\n",
       "      <td>Impossible Foods</td>\n",
       "      <td>US</td>\n",
       "      <td>Jaro-Winkler</td>\n",
       "      <td>0.96</td>\n",
       "      <td>Matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17312</td>\n",
       "      <td>VALEO</td>\n",
       "      <td>FR</td>\n",
       "      <td>357006</td>\n",
       "      <td>Paleo</td>\n",
       "      <td>BE</td>\n",
       "      <td>Levenshtein</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Not Matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17406</td>\n",
       "      <td>MEURA</td>\n",
       "      <td>BE</td>\n",
       "      <td>586864</td>\n",
       "      <td>Heura</td>\n",
       "      <td>ES</td>\n",
       "      <td>Levenshtein</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Not Matched</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   applicant_id         applicant_name applicant_ctry_code     UID   \n",
       "0      50051403  Impossible Foods Inc.                  US  765140  \\\n",
       "1         17312                  VALEO                  FR  357006   \n",
       "2         17406                  MEURA                  BE  586864   \n",
       "\n",
       "        CompanyName Country/Region    Match Type  Score Location Match  \n",
       "0  Impossible Foods             US  Jaro-Winkler   0.96        Matched  \n",
       "1             Paleo             BE   Levenshtein   1.00    Not Matched  \n",
       "2             Heura             ES   Levenshtein   1.00    Not Matched  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fuzzy['Location Match'] = df_fuzzy.apply(lambda row: match_quality(row['applicant_ctry_code'], row['Country/Region']), axis=1)\n",
    "df_fuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Disambiguate on Goodness of Name and Location Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 497.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>applicant_name</th>\n",
       "      <th>applicant_ctry_code</th>\n",
       "      <th>UID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Match Type</th>\n",
       "      <th>Score</th>\n",
       "      <th>Location Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17312</td>\n",
       "      <td>VALEO</td>\n",
       "      <td>FR</td>\n",
       "      <td>357006</td>\n",
       "      <td>Paleo</td>\n",
       "      <td>BE</td>\n",
       "      <td>Levenshtein</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Not Matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17406</td>\n",
       "      <td>MEURA</td>\n",
       "      <td>BE</td>\n",
       "      <td>586864</td>\n",
       "      <td>Heura</td>\n",
       "      <td>ES</td>\n",
       "      <td>Levenshtein</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Not Matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50051403</td>\n",
       "      <td>Impossible Foods Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>765140</td>\n",
       "      <td>Impossible Foods</td>\n",
       "      <td>US</td>\n",
       "      <td>Jaro-Winkler</td>\n",
       "      <td>0.96</td>\n",
       "      <td>Matched</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   applicant_id         applicant_name applicant_ctry_code     UID   \n",
       "1         17312                  VALEO                  FR  357006  \\\n",
       "2         17406                  MEURA                  BE  586864   \n",
       "0      50051403  Impossible Foods Inc.                  US  765140   \n",
       "\n",
       "        CompanyName Country/Region    Match Type  Score Location Match  \n",
       "1             Paleo             BE   Levenshtein   1.00    Not Matched  \n",
       "2             Heura             ES   Levenshtein   1.00    Not Matched  \n",
       "0  Impossible Foods             US  Jaro-Winkler   0.96        Matched  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create optimality metric as the cartesian distance of the match (Type, Location) score from (3, 3) which is the maximum attainable.\n",
    "d_loc = {'Not Matched': 1, 'Inconclusive':2, 'Matched':3}\n",
    "d_type = {'Levenshtein':1, 'Jaro-Winkler':2, 'Alphanumeric':3}\n",
    "disamb_df_fuzzy = df_fuzzy.copy()\n",
    "disamb_df_fuzzy['opt_distance'] = np.sqrt((disamb_df_fuzzy['Location Match'].map(d_loc))**2 + (disamb_df_fuzzy['Match Type'].map(d_type))**2)\n",
    "\n",
    "# Ensure that one company maps exactly on one applicant, then that one applicant maps exactly on one comapny. \n",
    "# Note that idmin() will return the index of the first occurrence of the minimum value, with no tie handling\n",
    "for col in tqdm(['UID', 'applicant_id']):\n",
    "    idx_min_rows = disamb_df_fuzzy.groupby(col)['opt_distance'].idxmin()\n",
    "    disamb_df_fuzzy = disamb_df_fuzzy.loc[idx_min_rows]\n",
    "\n",
    "# Display the result\n",
    "disamb_df_fuzzy.drop('opt_distance', axis=1, inplace=True)\n",
    "disamb_df_fuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Opportunities for Further Elaborations\n",
    "Use the threshold to filter, then the country code, then filter on industry information. \n",
    "Look at IPC class in patstat, it's not industry but they are activities related to the industry, so that you know food companies would only patent in certain classes \n",
    "and biotech companies would only patent in those other classes. \n",
    "Identify IPC classes in which food & beverage firms would make a patent, but the name and the courty code is good enough for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Final Files Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final output:\n",
    "\n",
    "The output should be a table with CrunchBase company ID, name, country, year of fundation and PATSTAT applicant ID, name, address country. Then it should include the type of match, and the filtering criterion.\n",
    "\n",
    "\n",
    "1. Add a column to the excel file where you identify whether the firm has a patent or not. Write type of match, score of match, whether coutry and region was correct. \n",
    "2. For those with a patent, the output should look like the sample patent shared with me - patent number, applicant ID etc etc. that's the real final file. \n",
    "3. Make the four output files in the examples. \n",
    "4. write what you did and why for a person who does not know much about programming. This can be done after hadning in the files.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Columns to pBook File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Brief Description</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Website</th>\n",
       "      <th>Year Founded</th>\n",
       "      <th>Matched</th>\n",
       "      <th>Match Type</th>\n",
       "      <th>Score</th>\n",
       "      <th>Location Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>657135</td>\n",
       "      <td>100Foods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil-based company that produces plant-based...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>São Paulo</td>\n",
       "      <td>https://www.100foods.com.br/</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>769415</td>\n",
       "      <td>108Labs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US-based company creating cultivated human milk</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Davis</td>\n",
       "      <td>https://108labs.net/</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>938559</td>\n",
       "      <td>1Ness Foods Pvt. Ltd.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India-based producer of plant-based dairy alte...</td>\n",
       "      <td>India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>https://1ness.in/</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>326285</td>\n",
       "      <td>3D Bio-Tissues Ltd.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U.K.-based research entity aimed at improving ...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Newcastle</td>\n",
       "      <td>https://www.3dbiotissues.com/</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>832680</td>\n",
       "      <td>4U Free From</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spain-based company producing a variety of veg...</td>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alicante</td>\n",
       "      <td>https://4ufreefrom.com/en/</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>978656</td>\n",
       "      <td>Zero Meat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan-based company producing soy meat products</td>\n",
       "      <td>Japan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://zeromeat.jp/</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>551962</td>\n",
       "      <td>ZhenMeat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China-based company producing domestic plant-b...</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>https://zhenmeat.com/en</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>833239</td>\n",
       "      <td>Zikooin Company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Korea-based company producing plant-base...</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>www.unlimeat.com</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>653912</td>\n",
       "      <td>Zoglo's (brand of Soglowek)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Produces frozen soy-based meats, including hot...</td>\n",
       "      <td>Canada</td>\n",
       "      <td>ON</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>http://www.zoglos.com/</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>406887</td>\n",
       "      <td>Zona Cerealista</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil-based \"virtual cereal warehouse\" that s...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vila Maria Alta</td>\n",
       "      <td>https://www.zonacerealista.com.br</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1476 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UID                  CompanyName Brand Name   \n",
       "0     657135                     100Foods        NaN  \\\n",
       "1     769415                      108Labs        NaN   \n",
       "2     938559       1Ness Foods Pvt. Ltd.         NaN   \n",
       "3     326285          3D Bio-Tissues Ltd.        NaN   \n",
       "4     832680                 4U Free From        NaN   \n",
       "...      ...                          ...        ...   \n",
       "1471  978656                    Zero Meat        NaN   \n",
       "1472  551962                     ZhenMeat        NaN   \n",
       "1473  833239              Zikooin Company        NaN   \n",
       "1474  653912  Zoglo's (brand of Soglowek)        NaN   \n",
       "1475  406887              Zona Cerealista        NaN   \n",
       "\n",
       "                                      Brief Description  Country/Region   \n",
       "0     Brazil-based company that produces plant-based...          Brazil  \\\n",
       "1       US-based company creating cultivated human milk   United States   \n",
       "2     India-based producer of plant-based dairy alte...          India    \n",
       "3     U.K.-based research entity aimed at improving ...  United Kingdom   \n",
       "4     Spain-based company producing a variety of veg...           Spain   \n",
       "...                                                 ...             ...   \n",
       "1471   Japan-based company producing soy meat products            Japan   \n",
       "1472  China-based company producing domestic plant-b...  Mainland China   \n",
       "1473  South Korea-based company producing plant-base...     South Korea   \n",
       "1474  Produces frozen soy-based meats, including hot...          Canada   \n",
       "1475  Brazil-based \"virtual cereal warehouse\" that s...          Brazil   \n",
       "\n",
       "           State             City                            Website   \n",
       "0            NaN        São Paulo       https://www.100foods.com.br/  \\\n",
       "1     California            Davis               https://108labs.net/   \n",
       "2            NaN           Mumbai                  https://1ness.in/   \n",
       "3            NaN        Newcastle      https://www.3dbiotissues.com/   \n",
       "4            NaN         Alicante         https://4ufreefrom.com/en/   \n",
       "...          ...              ...                                ...   \n",
       "1471         NaN              NaN               https://zeromeat.jp/   \n",
       "1472         NaN          Beijing            https://zhenmeat.com/en   \n",
       "1473         NaN            Seoul                   www.unlimeat.com   \n",
       "1474          ON          Toronto             http://www.zoglos.com/   \n",
       "1475         NaN  Vila Maria Alta  https://www.zonacerealista.com.br   \n",
       "\n",
       "      Year Founded  Matched Match Type  Score Location Match  \n",
       "0           2018.0    False        NaN    NaN            NaN  \n",
       "1           2013.0    False        NaN    NaN            NaN  \n",
       "2           2019.0    False        NaN    NaN            NaN  \n",
       "3           2019.0    False        NaN    NaN            NaN  \n",
       "4           2019.0    False        NaN    NaN            NaN  \n",
       "...            ...      ...        ...    ...            ...  \n",
       "1471        2018.0    False        NaN    NaN            NaN  \n",
       "1472        2017.0    False        NaN    NaN            NaN  \n",
       "1473        2017.0    False        NaN    NaN            NaN  \n",
       "1474        1987.0    False        NaN    NaN            NaN  \n",
       "1475        2012.0    False        NaN    NaN            NaN  \n",
       "\n",
       "[1476 rows x 13 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-import pBook File\n",
    "path = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\comlist_forpatent.xlsx' \n",
    "df_firms = pd.read_excel(path)\n",
    "df_firms\n",
    "\n",
    "# Perform a Left Join between pBook and disamb_df_fuzzy on UID\n",
    "right_merge = disamb_df_fuzzy.loc[:, ['UID', 'applicant_id', 'Match Type', 'Score', 'Location Match']]\n",
    "df_paste = pd.merge(df_firms, right_merge, on='UID', how='left')\n",
    "df_paste.rename(columns={'applicant_id':'Matched'}, inplace=True)\n",
    "df_paste['Matched'] = (~df_paste['Matched'].isna())\n",
    "df_paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write resulting dataframe to the output sheet of the pBook excel\n",
    "path = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Process Code - Michele\\comlist_forpatent result version.xlsx'\n",
    "sheet_name = 'Output Sheet'  # Replace with the desired sheet name\n",
    "\n",
    "# Write the DataFrame to the specified sheet\n",
    "with pd.ExcelWriter(path, engine='openpyxl', mode='w') as writer:\n",
    "    df_paste.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Produce Output pbookappln_ipc\n",
    "This table must have as headers the ID of an application, the symbol of its IPC class, and the count of how often that symbol appears in the database. All this data is found in  tls209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Internatonal Patent Classification Tab\n",
    "path_class1 = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Patstat2021a\\data_PATSTAT_Global_2021_Autumn\\tls209_part01.zip'\n",
    "csv_class1 = 'tls209_part01.csv'\n",
    "path_class2 = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Patstat2021a\\data_PATSTAT_Global_2021_Autumn\\tls209_part02.zip'\n",
    "csv_class2 = 'tls209_part02.csv'\n",
    "\n",
    "cols_people = ['appln_id', 'ipc_class_symbol']\n",
    "\n",
    "with zipfile.ZipFile(path_class1, 'r') as z:\n",
    "    with z.open(csv_class1) as f:\n",
    "            d_class1 = pd.read_csv(f, nrows=None, usecols=cols_people)\n",
    "        \n",
    "with zipfile.ZipFile(path_class2, 'r') as z:\n",
    "    with z.open(csv_class2) as f:\n",
    "            d_class2 = pd.read_csv(f, nrows=None, usecols=cols_people)\n",
    "\n",
    "# concatenate \n",
    "d_class = pd.concat([d_class1, d_class2], axis=0)\n",
    "del d_class1, d_class2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appln_id</th>\n",
       "      <th>ipc_class_symbol</th>\n",
       "      <th>IPC_macro_class_x</th>\n",
       "      <th>count</th>\n",
       "      <th>IPC_macro_class_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>G06K   7/00</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>G06K  17/00</td>\n",
       "      <td>6</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>G06K  19/077</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>H01R  12/18</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>H04M   1/02</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appln_id ipc_class_symbol  IPC_macro_class_x  count  IPC_macro_class_y\n",
       "0         1      G06K   7/00                  6     35                 35\n",
       "1         1      G06K  17/00                  6     98                 98\n",
       "2         1     G06K  19/077                  6     48                 48\n",
       "3         1      H01R  12/18                  1      3                  3\n",
       "4         1      H04M   1/02                  4     34                 34"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implement the procedure over the entire table\n",
    "pbookappln_ipc = d_class.groupby('ipc_class_symbol').count()\n",
    "pbookappln_ipc.rename(columns={'appln_id' : 'count'}, inplace=True)\n",
    "pbookappln_ipc = pd.merge(d_class, pbookappln_ipc, how='left', left_on='ipc_class_symbol', right_index=True)\n",
    "\n",
    "# Specify the desktop folder and save the DataFrame to a CSV file\n",
    "desktop_folder = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Process Code - Michele'  \n",
    "csv_file_path = f'{desktop_folder}/pbookapplnipc.csv'\n",
    "pbookappln_ipc.to_csv(csv_file_path, index=False)\n",
    "pbookappln_ipc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Produce Output pbookappln_ipc35\n",
    "The second and third position in the IPC_CLASS_SYMBOL string represent the application macro class from 01 to 99. I will retreive application ID, specify which IPC macro class they belong to - if it is withing the first 35. Then, outline the fraction of applicaitons in that macroclass with respect to all the applicaitons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appln_id</th>\n",
       "      <th>IPC_macro_class</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.06270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.13187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.05609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.02794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    appln_id  IPC_macro_class  frequency\n",
       "0          1                6    0.06270\n",
       "3          1                1    0.16903\n",
       "4          1                4    0.13187\n",
       "8          2                7    0.05609\n",
       "18         2               12    0.02794"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement the procedure over the entire database\n",
    "wdf = d_class.copy(deep=True)\n",
    "wdf['IPC_macro_class'] = wdf['ipc_class_symbol'].apply(lambda s: int(s[1:3]))\n",
    "wdf = wdf.groupby('IPC_macro_class').count()/wdf.shape[0]\n",
    "wdf.rename(columns={'appln_id':'frequency'}, inplace=True)\n",
    "wdf.reset_index(inplace=True)\n",
    "wdf = wdf.loc[wdf['IPC_macro_class']<=35, ['IPC_macro_class', 'frequency']]\n",
    "\n",
    "pbookappln_ipc35 = d_class\n",
    "pbookappln_ipc35['IPC_macro_class'] = pbookappln_ipc35['ipc_class_symbol'].apply(lambda s: int(s[1:3]))\n",
    "pbookappln_ipc35 = pd.merge(pbookappln_ipc35, wdf, how='left', on='IPC_macro_class')\n",
    "pbookappln_ipc35 = pbookappln_ipc35.loc[:, pbookappln_ipc35.columns!='ipc_class_symbol']\n",
    "pbookappln_ipc35.drop_duplicates(inplace=True) #here I am dropping duplicates,\n",
    "# if fact, one appln_ID could belong to more IPC classes, each mapping on the same Macro Class, with analogous frequence. Thus creating redundant records.\n",
    "\n",
    "# Specify the desktop folder and save the DataFrame to a CSV file\n",
    "desktop_folder = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Process Code - Michele'  \n",
    "csv_file_path = f'{desktop_folder}/pbookapplnipc35.csv'\n",
    "pbookappln_ipc35.to_csv(csv_file_path, index=False)\n",
    "pbookappln_ipc35.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Produce Output pbookcompanypat\n",
    "This table has the Company ID, Appln_ID, Family_ID, Earliest_Filing_Year, Filing Office, Count_References, Count_Citing, Grant_Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appln_id</th>\n",
       "      <th>receiving_office</th>\n",
       "      <th>earliest_filing_year</th>\n",
       "      <th>docdb_family_id</th>\n",
       "      <th>inpadoc_family_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1999</td>\n",
       "      <td>8554171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>1991</td>\n",
       "      <td>27517085</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>1999</td>\n",
       "      <td>7915918</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>1999</td>\n",
       "      <td>22889365</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appln_id receiving_office  earliest_filing_year  docdb_family_id   \n",
       "0         0                                   9999                0  \\\n",
       "1         1                                   1999          8554171   \n",
       "2         2                                   1991         27517085   \n",
       "3         3                                   1999          7915918   \n",
       "4         4                                   1999         22889365   \n",
       "\n",
       "   inpadoc_family_id  \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  2  \n",
       "3                  3  \n",
       "4                  4  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract Applications\n",
    "path_application1 = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Patstat2021a\\data_PATSTAT_Global_2021_Autumn\\tls201_part01.zip'\n",
    "csv_application1 = 'tls201_part01.csv'\n",
    "path_application2 = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Patstat2021a\\data_PATSTAT_Global_2021_Autumn\\tls201_part02.zip'\n",
    "csv_application2 = 'tls201_part02.csv'\n",
    "path_application3 = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Patstat2021a\\data_PATSTAT_Global_2021_Autumn\\tls201_part03.zip'\n",
    "csv_application3 = 'tls201_part03.csv'\n",
    "\n",
    "cols_application = ['appln_id', 'docdb_family_id', 'inpadoc_family_id', 'earliest_filing_year', 'receiving_office']\n",
    "\n",
    "with zipfile.ZipFile(path_application1, 'r') as z:\n",
    "    with z.open(csv_application1) as f:\n",
    "            d_application1 = pd.read_csv(f, nrows = None, usecols=cols_application)\n",
    "\n",
    "with zipfile.ZipFile(path_application2, 'r') as z:\n",
    "    with z.open(csv_application2) as f:\n",
    "            d_application2 = pd.read_csv(f, nrows = None, usecols=cols_application)\n",
    "\n",
    "with zipfile.ZipFile(path_application3, 'r') as z:\n",
    "    with z.open(csv_application3) as f:\n",
    "            d_application3 = pd.read_csv(f, nrows = 500, usecols=cols_application)\n",
    "\n",
    "# concatenate results\n",
    "d_application = pd.concat([d_application1, d_application2, d_application3], axis=0)\n",
    "del d_application1, d_application2, d_application3\n",
    "d_application.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>appln_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id  appln_id\n",
       "0          1         1\n",
       "1          1         7\n",
       "2          1        46\n",
       "3          1       775\n",
       "4          1      1192"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the Application-Person Link\n",
    "path_link = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Patstat2021a\\data_PATSTAT_Global_2021_Autumn\\tls207_part01.zip'\n",
    "csv_link = 'tls207_part01.csv'\n",
    "cols_link = ['person_id', 'appln_id']\n",
    "\n",
    "with zipfile.ZipFile(path_link, 'r') as z:\n",
    "    with z.open(csv_link) as f:\n",
    "            d_link = pd.read_csv(f, nrows = None, usecols=cols_link)\n",
    "d_link.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>appln_id</th>\n",
       "      <th>receiving_office</th>\n",
       "      <th>earliest_filing_year</th>\n",
       "      <th>docdb_family_id</th>\n",
       "      <th>inpadoc_family_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297418</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>1999</td>\n",
       "      <td>8554171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>297418</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>1999</td>\n",
       "      <td>10861834</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297418</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td></td>\n",
       "      <td>2002</td>\n",
       "      <td>9938265</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      UID  applicant_id  appln_id receiving_office  earliest_filing_year   \n",
       "0  297418             1         1                                   1999  \\\n",
       "1  297418             1         7                                   1999   \n",
       "2  297418             1        46                                   2002   \n",
       "\n",
       "   docdb_family_id  inpadoc_family_id  \n",
       "0          8554171                  1  \n",
       "1         10861834                  7  \n",
       "2          9938265                 46  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbookcompanypat = pd.merge(disamb_df_fuzzy[['UID', 'applicant_id']], d_link, left_on='applicant_id', right_on='person_id', how='inner').drop('person_id', axis=1)\n",
    "pbookcompanypat = pd.merge(pbookcompanypat, d_application, on='appln_id', how='inner')\n",
    "\n",
    "# Specify the desktop folder and save the DataFrame to a CSV file\n",
    "desktop_folder = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Process Code - Michele'  \n",
    "csv_file_path = f'{desktop_folder}/pbookcompanypat.csv'\n",
    "pbookcompanypat.to_csv(csv_file_path, index=False)\n",
    "pbookcompanypat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Produce Output pbookmatchfinal\n",
    "This table has Company ID, year founded, (year closed), (pbookcy), pbookname, patstat name, type match, (person_ID, patent cy, has patents, type match2). \n",
    "I will use this table to return my results in their entirety. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Website</th>\n",
       "      <th>Year Founded</th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>applicant_name</th>\n",
       "      <th>applicant_ctry_code</th>\n",
       "      <th>Match Type</th>\n",
       "      <th>Score</th>\n",
       "      <th>Location Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>431107</td>\n",
       "      <td>Alt Co. (The Alt Company)</td>\n",
       "      <td>India</td>\n",
       "      <td>https://alt.company/</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>380</td>\n",
       "      <td>Alstom Technology Ltd</td>\n",
       "      <td>CH</td>\n",
       "      <td>Jaro-Winkler</td>\n",
       "      <td>0.801569</td>\n",
       "      <td>Not Matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>897234</td>\n",
       "      <td>Australia's Own</td>\n",
       "      <td>Australia</td>\n",
       "      <td>https://australiasownfoods.com.au/</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>486</td>\n",
       "      <td>Austriamicrosystems AG</td>\n",
       "      <td>AT</td>\n",
       "      <td>Jaro-Winkler</td>\n",
       "      <td>0.820504</td>\n",
       "      <td>Not Matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297418</td>\n",
       "      <td>Kinda Co</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>https://www.thekindaco.com/</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Nokia Corporation</td>\n",
       "      <td>FI</td>\n",
       "      <td>Jaro-Winkler</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>Not Matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>499722</td>\n",
       "      <td>Luyef Biotechnologies, Inc.</td>\n",
       "      <td>Chile</td>\n",
       "      <td>https://luyef.com</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>26</td>\n",
       "      <td>Lucent Technologies Inc.</td>\n",
       "      <td>US</td>\n",
       "      <td>Jaro-Winkler</td>\n",
       "      <td>0.801569</td>\n",
       "      <td>Not Matched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184200</td>\n",
       "      <td>Marin Food</td>\n",
       "      <td>Japan</td>\n",
       "      <td>https://www.marinfood.co.jp/english/</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>46</td>\n",
       "      <td>Marioff Corporation Oy</td>\n",
       "      <td>FI</td>\n",
       "      <td>Jaro-Winkler</td>\n",
       "      <td>0.841667</td>\n",
       "      <td>Not Matched</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      UID                   CompanyName  Country/Region   \n",
       "0  431107     Alt Co. (The Alt Company)          India   \\\n",
       "1  897234               Australia's Own       Australia   \n",
       "2  297418                      Kinda Co  United Kingdom   \n",
       "3  499722  Luyef Biotechnologies, Inc.            Chile   \n",
       "4  184200                    Marin Food           Japan   \n",
       "\n",
       "                                Website  Year Founded  applicant_id   \n",
       "0                  https://alt.company/        2020.0           380  \\\n",
       "1    https://australiasownfoods.com.au/        2017.0           486   \n",
       "2           https://www.thekindaco.com/        2017.0             1   \n",
       "3                     https://luyef.com        2020.0            26   \n",
       "4  https://www.marinfood.co.jp/english/        1957.0            46   \n",
       "\n",
       "             applicant_name applicant_ctry_code    Match Type     Score   \n",
       "0     Alstom Technology Ltd                  CH  Jaro-Winkler  0.801569  \\\n",
       "1    Austriamicrosystems AG                  AT  Jaro-Winkler  0.820504   \n",
       "2         Nokia Corporation                  FI  Jaro-Winkler  0.810714   \n",
       "3  Lucent Technologies Inc.                  US  Jaro-Winkler  0.801569   \n",
       "4    Marioff Corporation Oy                  FI  Jaro-Winkler  0.841667   \n",
       "\n",
       "  Location Match  \n",
       "0    Not Matched  \n",
       "1    Not Matched  \n",
       "2    Not Matched  \n",
       "3    Not Matched  \n",
       "4    Not Matched  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_merge = disamb_df_fuzzy.loc[:, ['UID', 'applicant_id', 'applicant_name', 'applicant_ctry_code', 'Match Type', 'Score', 'Location Match']]\n",
    "left_merge = df_firms.loc[:, ['UID', 'CompanyName', 'Country/Region', 'Website', 'Year Founded']]\n",
    "pbookmatchfinal = pd.merge(left_merge, right_merge, on='UID', how='inner')\n",
    "\n",
    "# Specify the desktop folder and save the DataFrame to a CSV file\n",
    "desktop_folder = r'C:\\Users\\User\\Dropbox\\My PC (HP-16340)\\Desktop\\Work\\Dropbox\\Patent name match\\Process Code - Michele'  \n",
    "csv_file_path = f'{desktop_folder}/pbookmatchfinal.csv'\n",
    "pbookmatchfinal.to_csv(csv_file_path, index=False)\n",
    "pbookmatchfinal.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
