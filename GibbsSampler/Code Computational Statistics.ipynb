{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79dc6464",
   "metadata": {},
   "source": [
    "## Metropolis Hastings Algorithm ##\n",
    "#### As follows the the reader finds a description of the implementation of Metropolis Hastings Algoritm. Some pieces of code have been commented out, they are meant to swap between real and generated datasets, and beween the informative and noninformative priors as described in the report results. Currently, the code is set to return evaluations on generated data by using informative priors. Also, after the main algorithmic function, auxiliary methods are defined in the order they are called. ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3cf2f0",
   "metadata": {},
   "source": [
    "### Preliminary Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c79be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Relevant Libraries ###\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.discrete.discrete_model import Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27399d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #INITIALIZE REAL DATA\n",
    "    \n",
    "    #Retreive the Data from the excel file in excelpath, for simplicity we import only the first 50 lines\n",
    "    # notes, X must be full rank, the excel file has been handed in with the report\n",
    "#     df = pd.read_excel(excelpath)\n",
    "#     Y = df.loc[:49,'Is Male?'].values.astype(np.float64)\n",
    "#     X1 = pd.DataFrame(np.ones(50), columns = ['intercept'])\n",
    "#     X2 = df.loc[:49, ['education_level', 'hourly_income', 'restaurant_per_day', 'coffees_per_day']]\n",
    "#     X = pd.merge(X1, X2, left_index = True, right_index = True).values.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf16c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERATE TEST DATA\n",
    "\n",
    "#Generate X as uniform (0,1) distributed, let the true beta be [0.14, 0.12, 0.06, 0.38, 0.3], use it generate \n",
    "#the bernulli probabilities and sample the vector Y. Again, include a column of ones in X\n",
    "X1 = np.random.uniform(0, 1, (50,4))\n",
    "X2 = np.ones(50)\n",
    "X = np.insert(X1, 0, X2, axis = 1)\n",
    "real_beta = np.array([0.14, 0.12, 0.06, 0.38, 0.3])\n",
    "p = sp.stats.norm.cdf(X.dot(real_beta))\n",
    "Y = np.zeros(len(p))\n",
    "for i in range(len(p)):\n",
    "    Y[i] = np.random.binomial(1, p[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c317b",
   "metadata": {},
   "source": [
    "### Metropolis Hastings Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2dfa5d",
   "metadata": {},
   "source": [
    "##### Define Functions for the MH-Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7f0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q(X, Y, tau, Beta, precision):\n",
    "\n",
    "    #Action: return a random Beta_candidate from N(Beta, tau*{[I(Beta)]^-1})\n",
    "\n",
    "    return np.random.multivariate_normal(mean = Beta, cov = variance(X, Y, tau, Beta, precision)) \n",
    "\n",
    "def variance(X, Y, tau, Beta, precision):\n",
    "    \n",
    "    #Action : returns the inverse of the Fisher Score Matrix evaluated at that Beta\n",
    "    \n",
    "    # Generate the Fisher Score Matrix, stabilize p when it grows too close to 1 or 0, same goes for the second term\n",
    "    # to ensure convergence of the inversion algorthm\n",
    "    p = sp.stats.norm.cdf(X.dot(Beta))\n",
    "    p[p>1-precision] = 1-precision\n",
    "    p[p<0+precision] = 0+precision\n",
    "    \n",
    "    W = (1/(p*(1-p)))*np.diag(sp.stats.norm.pdf(sp.stats.norm.ppf(p))**2)\n",
    "    I = X.T @ W @ X\n",
    "    \n",
    "    # Transform the Fisher Score Matrix (I) into the variance of the proposal distribution\n",
    "    var = (tau * np.linalg.inv(I))\n",
    "    return var\n",
    "\n",
    "def alpha(X, Y, Beta, Beta_candidate):\n",
    "    \n",
    "    #Action: given the current value of Beta and its candidate value, \n",
    "    #        computs the alpha according to the formula from the slides \n",
    "    \n",
    "    return min(1, posterior(X, Y, Beta_candidate)/posterior(X, Y, Beta)) \n",
    "\n",
    "def posterior(X, Y, Beta):\n",
    "\n",
    "    # Action: returns the posterior probability of Beta as computed through the formula on the slides\n",
    "    \n",
    "    return (((sp.stats.norm.cdf(X.dot(Beta)))**Y)*((1-sp.stats.norm.cdf(X.dot(Beta)))**(1-Y))).prod() * prior(Beta) \n",
    "    \n",
    "def prior(Beta):\n",
    "    # Action: returns the prior probability of Beta as specified by the Decision Maker, \n",
    "    # in this case we pick a multinariate normal with high variance\n",
    "    \n",
    "      # NON_INFORMATIVE PRIORS: the following code is to be used when the prior is meant to be noninformative\n",
    "#     Cov = np.array([[ 0., -9.90046474, 5.52025854, -0.3783414,  4.72113058],\n",
    "#                     [ 9.18048934,  0., 4.44209061,  6.03586419, 7.85665877],\n",
    "#                     [ 5.91231272, -5.92272759, 0., -7.59668468, 5.67554438],\n",
    "#                     [ 1.10847662, -6.87587458, -9.43656676, 0., 1.54521851],\n",
    "#                     [ 9.15512171, -1.85204579, -3.93767116, 3.04618583, 0.]], dtype = np.float64)\n",
    "#     return sp.stats.multivariate_normal.pdf(Beta, np.ones(len(Beta)), 2000 * np.identity(len(Beta)) +  Cov) \n",
    "    \n",
    "    # INFORMATIVE PRIORS: the following code is to be used when the prior is meant to be informative    \n",
    "    return sp.stats.multivariate_normal.pdf(Beta, np.ones(len(Beta)), 2 * np.identity(len(Beta)))  \n",
    "\n",
    "def diagnostics(result, num_accepted, num_output):\n",
    "    \n",
    "    #Diagnostic 1: Acceptance rate\n",
    "    rate_accepted = num_accepted / (num_output + 1)\n",
    "    print(f'the acceptance rate is: {rate_accepted}')\n",
    "    \n",
    "    # Diagnostic 2: Time Series of the Marginal Distributions of Beta Entries, visual inspection for convergence\n",
    "    figure, axis = plt.subplots(len(result[0]))\n",
    "    Beta_series = [[] for p in range(len(result[0]))]\n",
    "    time_index = [t for t in range(len(result))]\n",
    "    \n",
    "    for p in range(len(result[0])):\n",
    "        for t in range(len(result)):\n",
    "            Beta_series[p].append(result[t][p])\n",
    "        axis[p].plot(time_index, Beta_series[p])\n",
    "        #axis[p].set_title(f'Beta {p}')\n",
    "        \n",
    "    figure.set_figheight(15)\n",
    "    figure.set_figwidth(15)\n",
    "    plt.subplots_adjust(left=1.1, bottom=1.1, right=1.9, top=1.9, wspace=0.4, hspace=0.4)\n",
    "\n",
    "    #Diagnostic 3: Means and variances of the Betas\n",
    "    means = [0 for _ in range(len(result[0]))]\n",
    "    variances = [0 for _ in range(len(result[0]))]\n",
    "    for j in range(len(result[0])):\n",
    "        for x in result:\n",
    "            means[j] += x[j]\n",
    "        means[j] = means[j]/len(result)\n",
    "    for j in range(len(result[0])):\n",
    "        for x in result:\n",
    "            variances[j] += (x[j] - means[j])**2\n",
    "        variances[j] = variances[j]/(len(result)-1)\n",
    "    print(f'the means of betas are: {means}')\n",
    "    print(f'the variances of betas are: {variances}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06511a",
   "metadata": {},
   "source": [
    "##### Define the MH-Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e7973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MH_Algo(tau, excelpath, num_output, precision):\n",
    "\n",
    "    # initiate iteration to 0,\n",
    "    # initialize the number of Betas accepted to 0\n",
    "    # set a random seed for reproducibility, \n",
    "    # check whether precision is small enough\n",
    "    np.random.seed(1)\n",
    "    Beta = Probit(Y, X).fit().params\n",
    "    result = []\n",
    "    iteration = 0\n",
    "    num_accepted = 0\n",
    "    if precision > 1e-1:\n",
    "        raise ValueError (f'precision must be lower than 0.1 while it now is {precision}')\n",
    "    \n",
    "    while iteration <= num_output:\n",
    "        iteration += 1\n",
    "        Beta_candidate = q(X, Y, tau, Beta, precision)\n",
    "        u = np.random.rand()\n",
    "        if u < alpha(X, Y, Beta, Beta_candidate):\n",
    "            Beta = Beta_candidate\n",
    "            num_accepted += 1\n",
    "            if iteration > 0.2*num_output: #do not include the warm up period in the estimation of posterior functionals\n",
    "                result.append(list(Beta))\n",
    "    \n",
    "    #DIAGNOSTICS:\n",
    "    \n",
    "    diagnostics(result, num_accepted, num_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0608b6e",
   "metadata": {},
   "source": [
    "#### In the following tab, the user can parametrize and call the algorithm to view its results, obviously, the excel file path has to be tailored to the one on the user's  computer ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb594343",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tau = 1e-3\n",
    "num_output = 10000\n",
    "excelpath = \".\\Statistics and Probability\\\\DataBase for MH-Algorithm.xlsx\"\n",
    "precision = 1e-15\n",
    "MH_Algo(tau, excelpath, num_output, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e3ac7",
   "metadata": {},
   "source": [
    "#### In this last tab, the user finds the code used to conjecture the relationship beteween tau and the acceptance rate. ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9097a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RELATION TAU, ACCEPTANCE RATE ### \n",
    "\n",
    "# Note. To run this script the MH-Alorithm must be changes so that no diagnostics are run\n",
    "# and the function actually return the acceptance rate. \n",
    "\n",
    "num_output = 100\n",
    "precision = 1e-15\n",
    "excelpath = \".\\Statistics and Probability\\\\DataBase for MH-Algorithm.xlsx\" \n",
    "TU = np.arange(-10, 10, 0.0001)\n",
    "AR = np.zeros(len(TU))\n",
    "i = 0\n",
    "for tau in TU:\n",
    "    try:\n",
    "        AR[i] = MH_Algo(tau, excelpath, num_output, precision)\n",
    "    except Exception:\n",
    "        AR[i] = AR[i-1]\n",
    "    i += 1\n",
    "    \n",
    "plt.plot(TU, AR)\n",
    "plt.title('Acceptance Rate As a Function of Tau')\n",
    "plt.xlabel('tau')\n",
    "plt.ylabel('acceptance rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc239c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
