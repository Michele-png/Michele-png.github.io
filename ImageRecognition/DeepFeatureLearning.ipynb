{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d197c51a-bac7-4a10-8f52-d79ae210f1b6",
   "metadata": {},
   "source": [
    "# Learning Deep Features\n",
    "###### Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.[1] For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. This area of research bears some relation to the long history of psychological literature on transfer of learning, although practical ties between the two fields are limited. From the practical standpoint, reusing or transferring information from previously learned tasks for the learning of new tasks has the potential to significantly improve the sample efficiency of a reinforcement learning agent.[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b25546-c90c-4863-95a2-819e890f44b2",
   "metadata": {},
   "source": [
    "## 1. Data Preparation and Deep Features Extraction\n",
    "\n",
    "As follow images are imported, rendered into tensors, and their vector representation is extracted from VGG19. Then, Classes are selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd549bf-d7de-49d9-a542-3acae56a2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3fa4a5-8152-4caf-8863-1da96d95fdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('train.json')\n",
    "annotations = json.load(f)\n",
    "image_files = set(os.listdir('NEW'))\n",
    "\n",
    "image_IDs = {}\n",
    "\n",
    "for i in annotations['images']: # i['id']\n",
    "    if i['file_name'].split('/')[-1] in image_files:\n",
    "        image_IDs[i['id']] = i['file_name'].split('/')[-1]\n",
    "        \n",
    "imgID_catIDs = {}\n",
    "\n",
    "for j in annotations['annotations']:\n",
    "    if j['image_id'] in image_IDs.keys():\n",
    "        imgID_catIDs[image_IDs[j['image_id']]] = j['category_id']\n",
    "        \n",
    "catIDs_names = {}\n",
    "\n",
    "for r in annotations['categories']:\n",
    "    if r['id'] in imgID_catIDs.values():\n",
    "        catIDs_names[r['id']] = r['family']\n",
    "        \n",
    "dict_labels = {}\n",
    "\n",
    "for val in image_IDs.values():\n",
    "    dict_labels[val] = catIDs_names[imgID_catIDs[val]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f21990-77c6-47da-80ec-8021d650883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "\n",
    "def extract_feature(model, img):\n",
    "    feature = model.predict(img)[0]\n",
    "    feature /= np.linalg.norm(feature)  \n",
    "    return (feature)\n",
    "\n",
    "deep_features = []\n",
    "file_names = []\n",
    "animals = []\n",
    "\n",
    "for i, k in enumerate(dict_labels.keys()):\n",
    "    img_path = \"NEW/\" + k\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    deep_feature = extract_feature(model, x)\n",
    "    \n",
    "    deep_features.append(deep_feature)\n",
    "    file_names.append(k)\n",
    "    animals.append(dict_labels[k])\n",
    "    \n",
    "    sys.stdout.write(\"\\rFinished iteration: %i\" % i)\n",
    "    sys.stdout.flush() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd562ff-3a4c-49b5-9069-811202b3530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_features = [deep_features[i] for i in range(len(deep_features)) if animals[i]!= 'Scincidae' and animals[i]!= 'Anguidae']\n",
    "subset_animals = [animals[i] for i in range(len(animals)) if animals[i]!= 'Scincidae' and animals[i]!= 'Anguidae']\n",
    "\n",
    "# Label encoder of the animal name (to numbers first, then one-hot encoding).\n",
    "labels = LabelEncoder().fit_transform(subset_animals)\n",
    "\n",
    "# Generate Train set (70%), test set (30%)\n",
    "X_train, X_other, y_train, y_other = train_test_split(subset_features, labels, stratify = labels, test_size = 0.3, random_state = 999)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_other, y_other, stratify = y_other, test_size = 0.3333, random_state = 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da93e2b-5ce7-43c6-b6d6-0c4afc405003",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Classification\n",
    "Henceforth, four support vecor machines are run using four different kernels, their test accuracy is evaluated and their confusion matrices are represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2f4f4-7d5a-4080-bd11-5a0cabcafd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec4368-550a-4940-8c78-4a2ec55a42d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "accuracy_lin = linear.score(X_test, y_test)\n",
    "print('Accuracy Linear Kernel:', accuracy_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a624ff-268c-4286-810e-8cd8696e5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "accuracy_rbf = rbf.score(X_test, y_test)\n",
    "print('Accuracy Radial Basis Kernel:', accuracy_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aebe2d-3604-47b4-9b84-07605f8e238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "accuracy_poly = poly.score(X_test, y_test)\n",
    "print('Accuracy Polynomial Kernel:', accuracy_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3ab196-3dab-406e-9f36-c1d9e44dcafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "accuracy_sig = sig.score(X_test, y_test)\n",
    "print('Accuracy Sigmoid Kernel:', accuracy_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600c56a-4641-4d1e-a478-da8ff15c613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(sig, open('sigmoid.sav', 'wb'))\n",
    "pickle.dump(poly, open('polynomial.sav', 'wb'))\n",
    "pickle.dump(rbf, open('Radial.sav', 'wb'))\n",
    "pickle.dump(linear, open('linear.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a4524-12a2-43ca-a29d-e92bc8a1d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "linear_pred = linear.predict(X_test)\n",
    "poly_pred = poly.predict(X_test)\n",
    "rbf_pred = rbf.predict(X_test)\n",
    "sig_pred = sig.predict(X_test)\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "cm_lin = pd.DataFrame(confusion_matrix(y_test, linear_pred))\n",
    "heatmap = sns.heatmap(cm_lin/cm_lin.sum(axis=1), vmin=0, vmax=1, annot=True)\n",
    "plt.savefig(f'linear SVM accuracy {accuracy_lin}.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "cm_poly = pd.DataFrame(confusion_matrix(y_test, poly_pred))\n",
    "heatmap = sns.heatmap(cm_poly/cm_poly.sum(axis=1), vmin=0, vmax=1, annot=True)\n",
    "plt.savefig(f'Polynomial SVM accuracy {accuracy_poly}.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "cm_rbf = pd.DataFrame(confusion_matrix(y_test, rbf_pred))\n",
    "heatmap = sns.heatmap(cm_rbf/cm_rbf.sum(axis=1), vmin=0, vmax=1, annot=True)\n",
    "plt.savefig(f'Radial SVM accuracy {accuracy_rbf}.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "cm_sig = pd.DataFrame(confusion_matrix(y_test, sig_pred))\n",
    "heatmap = sns.heatmap(cm_sig/cm_sig.sum(axis=1), vmin=0, vmax=1, annot=True)\n",
    "plt.savefig(f'Sigmoid SVM accuracy {accuracy_sig}.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
