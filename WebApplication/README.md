<h2>JaidPhis Start up</h2>

<p>JaidPhis is a start up developing an AI model capable of analysing computer camera frames and diagnosing musculoskeletal disorder. Then, it can leverage this knowledge to devise a gamified recovery plan. To validate the B2B business model, a prototype was built and presented to HR directors. The following describes the MVP implementation.

<h3>Prototype Implementation</h3>
<p>As a matter of fact, no AI model was available to readily accomplysh the diagnostic task. To evade the matter, a twofold architecture was ideated. On the one side, the corporate client was to record himself for a minute with his laptop front camera. Then, this video was to be uploaded on the web application, which would display it back with postural lines overlaid. These lines are derived from a simplistic machine learning model existing in conventional python libraries. Given that the product would be presented during a video call, a cofounder would visually assess the posture of the HR responsible, and input a verbal description into an online database. Eventually, on the customer side, when the reproduction of the uploaded video is over, the app would pull the written feedback and display it as if it was the output of a multimodal model, thus simulating the functioning of the final product. Here follows a visual representation. </p>

---

<div align="center">
<img src="https://github.com/Michele-png/Michele-png.github.io/blob/main/Digital%20Resources/WebAppArchitecture.jpg" alt="Logo" width="500">
</div>


## JaidPhis Start-Up

JaidPhis is a start-up developing an AI model capable of analyzing computer camera frames and diagnosing musculoskeletal disorders. The system leverages this information to devise a gamified recovery plan. A prototype was built to validate the B2B business model and was presented to HR directors for feedback. Below is a description of the MVP implementation and its components.

---

### Prototype Implementation

The challenge was that no readily available AI model existed for the diagnostic task. To overcome this, a twofold architecture was created. Hereâ€™s how it works:

1. **Video Recording**: The corporate client records themselves using their laptop's front camera for one minute.
2. **Uploading the Video**: The client uploads the video to a web application.
3. **Postural Analysis**: The uploaded video is displayed with postural lines overlaid. These lines are derived from a simplified machine learning model using conventional Python libraries.
4. **Feedback**: During a video call, a co-founder visually assesses the HR director's posture and provides feedback via an online form.
5. **Simulating AI Output**: The app simulates the final product by displaying the co-founder's feedback as if it were the output from a multimodal AI model.

---
